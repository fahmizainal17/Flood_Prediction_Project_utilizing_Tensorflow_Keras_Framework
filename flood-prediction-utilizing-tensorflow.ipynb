{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73278,"databundleVersionId":8121328,"sourceType":"competition"}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datetime import date\n\n\"\"\"\nHi Welcome Everyone ðŸ¤´ Let's Deep Dive into Flood Prediction with Tensorflow\n\"\"\"\n\ntoday = date.today()\nformatted_date = \"/\" + today.strftime(\"%d-%m-%Y\").replace(\"-0\", \"-\")\nprint(\"Today's date:\", formatted_date)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:22.993956Z","iopub.execute_input":"2024-05-31T21:57:22.995053Z","iopub.status.idle":"2024-05-31T21:57:23.001519Z","shell.execute_reply.started":"2024-05-31T21:57:22.994995Z","shell.execute_reply":"2024-05-31T21:57:23.000305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout\nfrom tensorflow.keras.losses import Loss\nfrom tensorflow.keras.optimizers import Optimizer\nfrom tensorflow.keras.regularizers import Regularizer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport warnings\n\n# Configure warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\npd.options.mode.chained_assignment = None  # default='warn'\npd.set_option('display.max_columns', None)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:26.586121Z","iopub.execute_input":"2024-05-31T21:57:26.586532Z","iopub.status.idle":"2024-05-31T21:57:26.595372Z","shell.execute_reply.started":"2024-05-31T21:57:26.586498Z","shell.execute_reply":"2024-05-31T21:57:26.594071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the provided datasets\ntrain_df = pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/playground-series-s4e5/test.csv\")\n\ndatasets = {\n    \"train.csv\": train_df,\n    \"test.csv\": test_df\n}\n\ni = 0\n\nfor fname, df in datasets.items():\n    match = re.search('train|test', fname)\n    if match:\n        print(f\"Reading {match.group()} ..\")\n        i += 1\n\n        try:\n            # Drop all-empty columns\n            df.dropna(axis='columns', how='all', inplace=True)\n\n            print(f\"Successfully Read {match.group()}\")\n\n        except pd.errors.ParserError as e:\n            print(f\"Error processing {match.group()}: {e}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:29.107498Z","iopub.execute_input":"2024-05-31T21:57:29.107928Z","iopub.status.idle":"2024-05-31T21:57:31.464184Z","shell.execute_reply.started":"2024-05-31T21:57:29.107894Z","shell.execute_reply":"2024-05-31T21:57:31.463049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"train_df.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:33.384183Z","iopub.execute_input":"2024-05-31T21:57:33.385194Z","iopub.status.idle":"2024-05-31T21:57:33.441509Z","shell.execute_reply.started":"2024-05-31T21:57:33.385157Z","shell.execute_reply":"2024-05-31T21:57:33.440042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Brief Explanation of Columns\n\n| Header                               | Description                                                                              |\n|--------------------------------------|------------------------------------------------------------------------------------------|\n| MonsoonIntensity                     | The intensity of monsoon rains in the region                                             |\n| TopographyDrainage                   | The effectiveness of natural drainage systems in the terrain                             |\n| RiverManagement                      | Measures and policies in place for managing river flow and health                        |\n| Deforestation                        | The extent of deforestation in the area                                                  |\n| Urbanization                         | The level of urban development and expansion                                             |\n| ClimateChange                        | The impact of climate change on the region                                               |\n| DamsQuality                          | The quality and maintenance status of dams                                               |\n| Siltation                            | The degree of silt accumulation in water bodies                                          |\n| AgriculturalPractices                | The agricultural practices followed and their impact on the environment                   |\n| Encroachments                        | The extent of illegal or unauthorized land use                                           |\n| IneffectiveDisasterPreparedness      | The level of preparedness for natural disasters                                          |\n| DrainageSystems                      | The condition and effectiveness of artificial drainage systems                           |\n| CoastalVulnerability                 | The susceptibility of coastal areas to flooding and other climate impacts                |\n| Landslides                           | The frequency and impact of landslides in the region                                     |\n| Watersheds                           | The health and management of watershed areas                                             |\n| DeterioratingInfrastructure          | The condition of infrastructure and its ability to withstand environmental stress         |\n| PopulationScore                      | A score representing the impact of population density on flood risk                      |\n| WetlandLoss                          | The extent of wetland loss in the region                                                 |\n| InadequatePlanning                   | The effect of inadequate urban and environmental planning                                |\n| PoliticalFactors                     | The influence of political decisions and stability on flood management                   |\n| FloodProbability                     | The likelihood of flooding occurring in the area (target variable)                       |\n\nThis table provides a clear and concise description of each column in your dataset, making it easier to understand the data you are working with.","metadata":{}},{"cell_type":"markdown","source":"## Exploratory Data Analysis\n\nCheck descriptive statistics","metadata":{}},{"cell_type":"code","source":"train_df.describe().T","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:36.423511Z","iopub.execute_input":"2024-05-31T21:57:36.424303Z","iopub.status.idle":"2024-05-31T21:57:37.217750Z","shell.execute_reply.started":"2024-05-31T21:57:36.424263Z","shell.execute_reply":"2024-05-31T21:57:37.216573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:41.820378Z","iopub.execute_input":"2024-05-31T21:57:41.821149Z","iopub.status.idle":"2024-05-31T21:57:41.827553Z","shell.execute_reply.started":"2024-05-31T21:57:41.821113Z","shell.execute_reply":"2024-05-31T21:57:41.826555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:42.006806Z","iopub.execute_input":"2024-05-31T21:57:42.007241Z","iopub.status.idle":"2024-05-31T21:57:42.047923Z","shell.execute_reply.started":"2024-05-31T21:57:42.007212Z","shell.execute_reply":"2024-05-31T21:57:42.046898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{}},{"cell_type":"code","source":"missing_values = train_df.isnull().sum().sort_values(ascending=False)\npercentage_missing = (missing_values / len(train_df)) * 100\nmissing_info = pd.concat([missing_values, percentage_missing], axis=1)\nmissing_info.columns = ['Missing Values', 'Percentage Missing']\n\n# Format percentage_missing column with two decimal places and percentage symbol\nmissing_info['Percentage Missing'] = missing_info['Percentage Missing'].apply(lambda x: \"{:.2f}%\".format(x))\n\nprint(missing_info)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:42.288149Z","iopub.execute_input":"2024-05-31T21:57:42.288550Z","iopub.status.idle":"2024-05-31T21:57:42.320094Z","shell.execute_reply.started":"2024-05-31T21:57:42.288518Z","shell.execute_reply":"2024-05-31T21:57:42.318998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a backup first before running the code to retrieve back later the original one\ndf_backup = train_df.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:42.445641Z","iopub.execute_input":"2024-05-31T21:57:42.446077Z","iopub.status.idle":"2024-05-31T21:57:42.527543Z","shell.execute_reply.started":"2024-05-31T21:57:42.446043Z","shell.execute_reply":"2024-05-31T21:57:42.526554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.drop(\"id\",axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:42.620557Z","iopub.execute_input":"2024-05-31T21:57:42.620974Z","iopub.status.idle":"2024-05-31T21:57:42.688070Z","shell.execute_reply.started":"2024-05-31T21:57:42.620943Z","shell.execute_reply":"2024-05-31T21:57:42.687089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(3,7,figsize = (30,7))\nplt.subplots_adjust(left=0.05, right=0.95, top=0.9, bottom=0.05, wspace=0.3, hspace=0.4)\ni = 0\nj = 0\nfor column in train_df.columns:\n    sns.histplot(x = train_df[column] ,bins=train_df[column].nunique() ,ax=ax[i,j])\n    j+=1\n    if j > 6:\n        i+=1\n        j = 0","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:42.782318Z","iopub.execute_input":"2024-05-31T21:57:42.783003Z","iopub.status.idle":"2024-05-31T21:57:53.464426Z","shell.execute_reply.started":"2024-05-31T21:57:42.782967Z","shell.execute_reply":"2024-05-31T21:57:53.463251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(3,7,figsize = (30,7))\nplt.subplots_adjust(left=0.05, right=0.95, top=0.9, bottom=0.05, wspace=0.3, hspace=0.4)\ni = 0\nj = 0\nfor column in train_df.columns:\n    sns.boxplot(x = train_df[column] ,ax=ax[i,j])\n    j+=1\n    if j > 6:\n        i+=1\n        j = 0","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:53.466563Z","iopub.execute_input":"2024-05-31T21:57:53.467026Z","iopub.status.idle":"2024-05-31T21:57:57.929560Z","shell.execute_reply.started":"2024-05-31T21:57:53.466990Z","shell.execute_reply":"2024-05-31T21:57:57.928439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a backup first before running the code to retrieve back later the original one\ndf_backup = train_df.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:57.931025Z","iopub.execute_input":"2024-05-31T21:57:57.931423Z","iopub.status.idle":"2024-05-31T21:57:58.011807Z","shell.execute_reply.started":"2024-05-31T21:57:57.931390Z","shell.execute_reply":"2024-05-31T21:57:58.010680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.corr()[\"FloodProbability\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:58.014268Z","iopub.execute_input":"2024-05-31T21:57:58.014618Z","iopub.status.idle":"2024-05-31T21:57:59.486281Z","shell.execute_reply.started":"2024-05-31T21:57:58.014588Z","shell.execute_reply":"2024-05-31T21:57:59.485102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Before Dropping FloodProbability')\nplt.figure(figsize=(18,7))\ncorr = train_df.corr()\nmask = np.triu(corr)\nsns.heatmap(corr, mask = mask,linewidth=0.1 ,annot=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:57:59.487616Z","iopub.execute_input":"2024-05-31T21:57:59.487975Z","iopub.status.idle":"2024-05-31T21:58:02.154229Z","shell.execute_reply.started":"2024-05-31T21:57:59.487944Z","shell.execute_reply":"2024-05-31T21:58:02.153030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('After Dropping FloodProbability')\nplt.figure(figsize=(18,7))\ncorr = train_df.drop('FloodProbability', axis=1).corr()\nmask = np.triu(corr)\nsns.heatmap(corr, mask = mask,linewidth=0.1 ,annot=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:02.155759Z","iopub.execute_input":"2024-05-31T21:58:02.156216Z","iopub.status.idle":"2024-05-31T21:58:04.846911Z","shell.execute_reply.started":"2024-05-31T21:58:02.156177Z","shell.execute_reply":"2024-05-31T21:58:04.845776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy.random import seed\nfrom numpy.random import randn\nfrom numpy import mean\nfrom numpy import std\nout_per=[]\nnum_out_l = []\nnum_col = train_df.drop(\"FloodProbability\",axis=1).columns\nfor i in num_col:\n    \n    Q1,Q3=train_df[i].quantile(0.25),train_df[i].quantile(0.75)\n# identify outliers\n    \n    IQR=Q3-Q1\n    \n    lower,upper=Q1-1.5*IQR,Q3+1.5*IQR\n\n# identify outliers\n    outliers = [x for x in train_df[i] if x < lower or x > upper]\n    \n    num_out=len(outliers)\n    \n    outliers_removed = [x for x in train_df[i] if x >= lower and x <= upper]\n    num_nout=len(outliers_removed)\n    \n    outlier_percent=(num_out/(num_out+num_nout))\n    num_out_l.append(num_out)\n    out_per.append(outlier_percent)\n    \nprint(\"The Outliers in the Data\")    \n    \nOutliers=pd.DataFrame({'Feature':list(num_col),\"Num of Outliers\":num_out_l ,'% Of Outliers':out_per})\nOutliers","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:04.848252Z","iopub.execute_input":"2024-05-31T21:58:04.848672Z","iopub.status.idle":"2024-05-31T21:58:17.821295Z","shell.execute_reply.started":"2024-05-31T21:58:04.848643Z","shell.execute_reply":"2024-05-31T21:58:17.820209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a backup first before running the code to retrieve back later the original one\ndf_backup = train_df.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:17.822573Z","iopub.execute_input":"2024-05-31T21:58:17.822937Z","iopub.status.idle":"2024-05-31T21:58:17.896377Z","shell.execute_reply.started":"2024-05-31T21:58:17.822909Z","shell.execute_reply":"2024-05-31T21:58:17.895273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:17.897647Z","iopub.execute_input":"2024-05-31T21:58:17.897991Z","iopub.status.idle":"2024-05-31T21:58:17.946260Z","shell.execute_reply.started":"2024-05-31T21:58:17.897964Z","shell.execute_reply":"2024-05-31T21:58:17.944925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nclass OutlierRemover(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        num_cols = X.loc[:, \"MonsoonIntensity\":\"PoliticalFactors\"]\n        for column in num_cols.columns:\n            q75, q25 = np.percentile(X[column], [75, 25])\n            intr_qr = q75 - q25\n\n            max_val = q75 + (1.5 * intr_qr)\n            min_val = q25 - (1.5 * intr_qr)\n\n            X.loc[X[column] < min_val, column] = np.nan\n            X.loc[X[column] > max_val, column] = np.nan\n\n        X.dropna(inplace=True)\n        return X\n\nclass ScalingData(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        scaler = StandardScaler()\n        num_cols = X.loc[:, \"MonsoonIntensity\":\"PoliticalFactors\"].columns\n        X[num_cols] = scaler.fit_transform(X[num_cols])\n        return X","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:17.950173Z","iopub.execute_input":"2024-05-31T21:58:17.950549Z","iopub.status.idle":"2024-05-31T21:58:17.967006Z","shell.execute_reply.started":"2024-05-31T21:58:17.950517Z","shell.execute_reply":"2024-05-31T21:58:17.965743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a backup first before running the code to retrieve back later the original one\ndf_backup = train_df.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:17.968253Z","iopub.execute_input":"2024-05-31T21:58:17.968607Z","iopub.status.idle":"2024-05-31T21:58:18.054580Z","shell.execute_reply.started":"2024-05-31T21:58:17.968553Z","shell.execute_reply":"2024-05-31T21:58:18.053293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline_fit_transform = Pipeline([\n    (\"outlier_remover\", OutlierRemover()),\n    (\"scaling\", ScalingData())\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:18.056218Z","iopub.execute_input":"2024-05-31T21:58:18.056628Z","iopub.status.idle":"2024-05-31T21:58:18.063236Z","shell.execute_reply.started":"2024-05-31T21:58:18.056591Z","shell.execute_reply":"2024-05-31T21:58:18.061870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline_fit_transform.fit_transform(train_df)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:18.064920Z","iopub.execute_input":"2024-05-31T21:58:18.065986Z","iopub.status.idle":"2024-05-31T21:58:19.320364Z","shell.execute_reply.started":"2024-05-31T21:58:18.065947Z","shell.execute_reply":"2024-05-31T21:58:19.319232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize lists to store the results\nout_per = []\nnum_out_l = []\n\n# Extract column names excluding the target variable\nnum_col = train_df.drop(\"FloodProbability\", axis=1).columns\n\n# Loop through each numerical column to identify outliers\nfor col in num_col:\n    Q1, Q3 = train_df[col].quantile(0.25), train_df[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n\n    # Identify outliers\n    outliers = train_df[col][(train_df[col] < lower) | (train_df[col] > upper)]\n    num_out = len(outliers)\n\n    # Identify non-outliers\n    non_outliers = train_df[col][(train_df[col] >= lower) & (train_df[col] <= upper)]\n    num_nout = len(non_outliers)\n\n    # Calculate the percentage of outliers\n    outlier_percent = num_out / (num_out + num_nout)\n    num_out_l.append(num_out)\n    out_per.append(outlier_percent)\n\nprint(\"The Outliers in the Data\")\n\n# Create a DataFrame to summarize the outliers\nOutliers = pd.DataFrame({\n    'Feature': num_col,\n    'Num of Outliers': num_out_l,\n    '% of Outliers': out_per\n})\n\nOutliers\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:19.321881Z","iopub.execute_input":"2024-05-31T21:58:19.322317Z","iopub.status.idle":"2024-05-31T21:58:20.158521Z","shell.execute_reply.started":"2024-05-31T21:58:19.322279Z","shell.execute_reply":"2024-05-31T21:58:20.157496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a backup first before running the code to retrieve back later the original one\ndf_backup = train_df.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:20.159655Z","iopub.execute_input":"2024-05-31T21:58:20.159983Z","iopub.status.idle":"2024-05-31T21:58:20.278327Z","shell.execute_reply.started":"2024-05-31T21:58:20.159956Z","shell.execute_reply":"2024-05-31T21:58:20.277182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df.drop(\"FloodProbability\" ,axis = 1)\ny = train_df[\"FloodProbability\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:20.279536Z","iopub.execute_input":"2024-05-31T21:58:20.279868Z","iopub.status.idle":"2024-05-31T21:58:20.334280Z","shell.execute_reply.started":"2024-05-31T21:58:20.279841Z","shell.execute_reply":"2024-05-31T21:58:20.333208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Features (X):\")\nprint(X.head())\nprint(\"\\nTarget (y):\")\nprint(y.head())","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:20.335627Z","iopub.execute_input":"2024-05-31T21:58:20.336008Z","iopub.status.idle":"2024-05-31T21:58:20.351460Z","shell.execute_reply.started":"2024-05-31T21:58:20.335979Z","shell.execute_reply":"2024-05-31T21:58:20.350282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X ,y ,test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:20.352806Z","iopub.execute_input":"2024-05-31T21:58:20.353146Z","iopub.status.idle":"2024-05-31T21:58:20.682601Z","shell.execute_reply.started":"2024-05-31T21:58:20.353109Z","shell.execute_reply":"2024-05-31T21:58:20.681645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:20.683743Z","iopub.execute_input":"2024-05-31T21:58:20.684047Z","iopub.status.idle":"2024-05-31T21:58:20.872060Z","shell.execute_reply.started":"2024-05-31T21:58:20.684022Z","shell.execute_reply":"2024-05-31T21:58:20.870925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\ndef r2_score(y_true, y_pred):\n    SS_res =  tf.reduce_sum(tf.square(y_true - y_pred)) \n    SS_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true))) \n    return 1 - SS_res/(SS_tot + tf.keras.backend.epsilon())","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:20.873366Z","iopub.execute_input":"2024-05-31T21:58:20.873694Z","iopub.status.idle":"2024-05-31T21:58:20.879736Z","shell.execute_reply.started":"2024-05-31T21:58:20.873667Z","shell.execute_reply":"2024-05-31T21:58:20.878622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\n\n# Define the model\nmodel = Sequential([\n    Input(shape=(X.shape[1],)),  # Input layer with the shape matching the number of features\n    Dense(units=175, activation=\"relu\"),\n    Dense(units=75, activation=\"relu\"),\n    Dense(units=25, activation=\"relu\"),\n    Dense(units=1, activation=\"sigmoid\"),\n])\n\n# Compile the model\nmodel.compile(\n    optimizer=Adam(),\n    loss=BinaryCrossentropy(),\n    metrics=['accuracy']  # Using accuracy as the metric\n)\n\n# Display the model summary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:20.881225Z","iopub.execute_input":"2024-05-31T21:58:20.881539Z","iopub.status.idle":"2024-05-31T21:58:20.938628Z","shell.execute_reply.started":"2024-05-31T21:58:20.881487Z","shell.execute_reply":"2024-05-31T21:58:20.937642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train ,y_train ,epochs=10,batch_size=128 ,validation_data=(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:58:20.939907Z","iopub.execute_input":"2024-05-31T21:58:20.940231Z","iopub.status.idle":"2024-05-31T21:59:46.506489Z","shell.execute_reply.started":"2024-05-31T21:58:20.940205Z","shell.execute_reply":"2024-05-31T21:59:46.505240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test ,y_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:59:46.510932Z","iopub.execute_input":"2024-05-31T21:59:46.511282Z","iopub.status.idle":"2024-05-31T21:59:55.322538Z","shell.execute_reply.started":"2024-05-31T21:59:46.511255Z","shell.execute_reply":"2024-05-31T21:59:55.321548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_data = np.array([[0.05846292, 1.5502242, 0.0648132, 1.68311641, 0.54398045,\n                        -0.46230634, -0.4649187, -0.96303572, -0.96849213, -0.46063278,\n                        -1.4664417, 0.07144597, -0.96650463, -0.9570414, 0.04737342,\n                        -0.45419361, 1.062734, 0.06914986, 1.04863803, -0.95835143]])","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:59:55.324164Z","iopub.execute_input":"2024-05-31T21:59:55.324500Z","iopub.status.idle":"2024-05-31T21:59:55.330041Z","shell.execute_reply.started":"2024-05-31T21:59:55.324472Z","shell.execute_reply":"2024-05-31T21:59:55.328977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(input_data)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:59:55.331831Z","iopub.execute_input":"2024-05-31T21:59:55.332644Z","iopub.status.idle":"2024-05-31T21:59:55.455866Z","shell.execute_reply.started":"2024-05-31T21:59:55.332606Z","shell.execute_reply":"2024-05-31T21:59:55.454806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:59:55.457459Z","iopub.execute_input":"2024-05-31T21:59:55.457812Z","iopub.status.idle":"2024-05-31T21:59:55.476702Z","shell.execute_reply.started":"2024-05-31T21:59:55.457783Z","shell.execute_reply":"2024-05-31T21:59:55.475193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline_fit_transform_scaling = Pipeline([\n    (\"scaling\" ,Scaling_Data())\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:59:55.491059Z","iopub.execute_input":"2024-05-31T21:59:55.491403Z","iopub.status.idle":"2024-05-31T21:59:55.496565Z","shell.execute_reply.started":"2024-05-31T21:59:55.491377Z","shell.execute_reply":"2024-05-31T21:59:55.495331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline_fit_transform_scaling.fit_transform(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:59:55.498114Z","iopub.execute_input":"2024-05-31T21:59:55.498445Z","iopub.status.idle":"2024-05-31T21:59:55.794075Z","shell.execute_reply.started":"2024-05-31T21:59:55.498419Z","shell.execute_reply":"2024-05-31T21:59:55.792827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a backup first before running the code to retrieve back later the original one\ndf_backup = test_df.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:59:55.795601Z","iopub.execute_input":"2024-05-31T21:59:55.796128Z","iopub.status.idle":"2024-05-31T21:59:55.977503Z","shell.execute_reply.started":"2024-05-31T21:59:55.796086Z","shell.execute_reply":"2024-05-31T21:59:55.976383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = test_df[\"id\"]\ntest_df.drop(\"id\" ,axis = 1 ,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:59:55.978790Z","iopub.execute_input":"2024-05-31T21:59:55.979129Z","iopub.status.idle":"2024-05-31T21:59:56.087683Z","shell.execute_reply.started":"2024-05-31T21:59:55.979101Z","shell.execute_reply":"2024-05-31T21:59:56.086750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Prediction = model.predict(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T21:59:56.089020Z","iopub.execute_input":"2024-05-31T21:59:56.089353Z","iopub.status.idle":"2024-05-31T22:00:31.788862Z","shell.execute_reply.started":"2024-05-31T21:59:56.089326Z","shell.execute_reply":"2024-05-31T22:00:31.787680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Prediction = Prediction.flatten()","metadata":{"execution":{"iopub.status.busy":"2024-05-31T22:00:31.791050Z","iopub.execute_input":"2024-05-31T22:00:31.792058Z","iopub.status.idle":"2024-05-31T22:00:31.797104Z","shell.execute_reply.started":"2024-05-31T22:00:31.792016Z","shell.execute_reply":"2024-05-31T22:00:31.795912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Predictions = pd.DataFrame({\"id\":ids ,\"FloodProbability\":Prediction})","metadata":{"execution":{"iopub.status.busy":"2024-05-31T22:00:31.798691Z","iopub.execute_input":"2024-05-31T22:00:31.799375Z","iopub.status.idle":"2024-05-31T22:00:31.812097Z","shell.execute_reply.started":"2024-05-31T22:00:31.799337Z","shell.execute_reply":"2024-05-31T22:00:31.811134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Predictions","metadata":{"execution":{"iopub.status.busy":"2024-05-31T22:00:31.813369Z","iopub.execute_input":"2024-05-31T22:00:31.813683Z","iopub.status.idle":"2024-05-31T22:00:31.830495Z","shell.execute_reply.started":"2024-05-31T22:00:31.813658Z","shell.execute_reply":"2024-05-31T22:00:31.829363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Predictions.to_csv(\"submission_.csv\" ,index = False)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T22:11:47.559275Z","iopub.execute_input":"2024-05-31T22:11:47.559739Z","iopub.status.idle":"2024-05-31T22:11:48.771827Z","shell.execute_reply.started":"2024-05-31T22:11:47.559692Z","shell.execute_reply":"2024-05-31T22:11:48.770689Z"},"trusted":true},"execution_count":null,"outputs":[]}]}